{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea381447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 17:06:26.784 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Sourav Kamble\\Anaconda Prompt\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-10-29 17:06:26.815 Serialization of dataframe to Arrow table was unsuccessful due to: (\"Could not convert dtype('O') with type numpy.dtype[object_]: did not recognize Python value type when inferring an Arrow data type\", 'Conversion failed for column 0 with type object'). Applying automatic fixes for column types to make the dataframe Arrow-compatible.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries (Shell 1)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import streamlit as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, mean_squared_error\n",
    "import pickle\n",
    "\n",
    "# Load the dataset (Shell 2)\n",
    "df = pd.read_excel('Copper_Set.xlsx')\n",
    "\n",
    "# Data Understanding and Exploration (Shell 3)\n",
    "# Display the first few rows of the dataset\n",
    "st.write(\"Data preview:\")\n",
    "st.dataframe(df.head())\n",
    "\n",
    "# Identify the types of variables\n",
    "st.write(\"Data types:\")\n",
    "st.write(df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "st.write(\"Missing values:\")\n",
    "st.write(df.isna().sum())\n",
    "\n",
    "# Check for skewness and outliers using Seaborn charts\n",
    "sns.boxplot(data=df)\n",
    "plt.title('Boxplot to identify outliers')\n",
    "st.pyplot(plt)\n",
    "\n",
    "sns.histplot(df['selling_price'], kde=True)\n",
    "plt.title('Distribution of Selling Price')\n",
    "st.pyplot(plt)\n",
    "\n",
    "# Data Preprocessing (Shell 4)\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df['material_ref'] = imputer.fit_transform(df[['material_ref']])\n",
    "\n",
    "# Treat reference columns as categorical variables\n",
    "df['material_ref'] = df['material_ref'].astype('category')\n",
    "\n",
    "# Handle skewness using log transformation for 'selling_price'\n",
    "df['selling_price'] = np.log1p(df['selling_price'])\n",
    "\n",
    "# Encoding categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['status'] = label_encoder.fit_transform(df['status'])\n",
    "\n",
    "# Split the dataset into train and test sets (Shell 5)\n",
    "X = df.drop(['selling_price', 'status'], axis=1)\n",
    "y_regression = df['selling_price']\n",
    "y_classification = df['status']\n",
    "\n",
    "X_train, X_test, y_train_reg, y_test_reg = train_test_split(X, y_regression, test_size=0.2, random_state=42)\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X, y_classification, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Regression Model (Shell 6)\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "regressor.fit(X_train_scaled, y_train_reg)\n",
    "y_pred_reg = regressor.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "st.write(f'Mean Squared Error (Regression Model): {mse}')\n",
    "\n",
    "# Classification Model (Shell 7)\n",
    "classifier = ExtraTreesClassifier(random_state=42)\n",
    "classifier.fit(X_train_class, y_train_class)\n",
    "y_pred_class = classifier.predict(X_test_class)\n",
    "\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "precision = precision_score(y_test_class, y_pred_class)\n",
    "recall = recall_score(y_test_class, y_pred_class)\n",
    "f1 = f1_score(y_test_class, y_pred_class)\n",
    "st.write(f'Accuracy: {accuracy}')\n",
    "st.write(f'Precision: {precision}')\n",
    "st.write(f'Recall: {recall}')\n",
    "st.write(f'F1 Score: {f1}')\n",
    "\n",
    "# Save models and encoders using Pickle (Shell 8)\n",
    "with open('regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(regressor, f)\n",
    "with open('classification_model.pkl', 'wb') as f:\n",
    "    pickle.dump(classifier, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Streamlit User Interface (Shell 9)\n",
    "def predict(input_data, task):\n",
    "    if task == 'Regression':\n",
    "        model = pickle.load(open('regression_model.pkl', 'rb'))\n",
    "        prediction = model.predict(scaler.transform(input_data))\n",
    "        prediction = np.expm1(prediction)  # Reverse transformation of log to get original scale\n",
    "        return prediction\n",
    "    elif task == 'Classification':\n",
    "        model = pickle.load(open('classification_model.pkl', 'rb'))\n",
    "        prediction = model.predict(input_data)\n",
    "        return label_encoder.inverse_transform(prediction)\n",
    "\n",
    "# Interactive Streamlit App\n",
    "st.title(\"Industrial Copper Modeling Prediction\")\n",
    "\n",
    "# User input fields for model prediction\n",
    "task = st.selectbox('Choose a task', ['Regression', 'Classification'])\n",
    "input_data = []\n",
    "for column in X.columns:\n",
    "    value = st.text_input(f'Enter value for {column}:')\n",
    "    input_data.append(value)\n",
    "\n",
    "input_data = np.array(input_data).reshape(1, -1)\n",
    "if st.button('Predict'):\n",
    "    result = predict(input_data, task)\n",
    "    st.write(f'Prediction: {result}')\n",
    "\n",
    "# Visualizations (Shell 10)\n",
    "labels = ['WON', 'LOST']\n",
    "values = df['status'].value_counts().tolist()\n",
    "plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Classification of Status')\n",
    "st.pyplot(plt)\n",
    "\n",
    "sns.scatterplot(data=df, x='thickness', y='selling_price')\n",
    "plt.title('Thickness vs Selling Price')\n",
    "st.pyplot(plt)\n",
    "\n",
    "# Readme for GitHub (Shell 11)\n",
    "readme_content = \"\"\"\n",
    "# Industrial Copper Modeling Project\n",
    "\n",
    "This project addresses the challenges in the copper industry by building a regression model to predict selling prices and a classification model to classify lead status as WON or LOST. \n",
    "\n",
    "### Steps\n",
    "1. **Data Understanding**: Performed data exploration to understand variable types and their distributions.\n",
    "2. **Data Preprocessing**: Handled missing values, skewness, and encoded categorical variables.\n",
    "3. **EDA**: Used Seaborn to visualize the data.\n",
    "4. **Model Building**: Built Regression and Classification models using tree-based algorithms.\n",
    "5. **Web App with Streamlit**: Created an interactive page for regression and classification predictions.\n",
    "\n",
    "#### Usage\n",
    "- Install necessary libraries using `requirements.txt`\n",
    "- Run the notebook to train the models and save them.\n",
    "- Use `streamlit run app.py` to deploy the web application.\n",
    "\n",
    "### Project Evaluation Metrics\n",
    "- Regression model: Mean Squared Error\n",
    "- Classification model: Accuracy, Precision, Recall, F1 Score\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Save README.md\n",
    "with open('README.md', 'w') as readme_file:\n",
    "    readme_file.write(readme_content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
